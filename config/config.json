{
  "server": {
    "port": 8080
  },
  "llm": {
    "provider": "ollama",
    "enable_reasoning": false,
    "ollama": {
      "enabled": true,
      "endpoint": "http://localhost:11434",
      "model": "qwen3:14b",
      "max_tokens": 4096,
      "timeout_seconds": 100
    }
  }
}
